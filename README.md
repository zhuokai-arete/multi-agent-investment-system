# Multi-Agent Investment System

A modular, extensible portfolio management system integrating multiple investment strategies, including Risk Parity, CVaR-based risk control, and reinforcement learning (PPO). The system is designed to support strategy diversity, dynamic decision fusion, and future expansion into cooperative/competitive multi-agent architectures.

## ğŸ“Œ Project Overview

This project explores how rule-based strategies and reinforcement learning agents can be integrated into a multi-agent investment decision-making framework. The system is structured to allow comparative evaluation, strategy fusion, and scalable extension toward more complex agent interactions.

## âš™ï¸ Core Components

- `RiskParityAgent`: Allocates asset weights by minimizing portfolio variance under a risk parity constraint.
- `CVaRDownsideVolAgent`: Implements tail-risk-aware decisions using Conditional Value at Risk and downside volatility, with automatic cash-holding triggers.
- `PPOAgent`: A continuous-action actor-critic agent trained with portfolio-level reward signals, including return, risk penalty, and transaction costs.

## ğŸ§  Current Capabilities

- Modular agent interface and unified control loop via `DebateRoom` controller.
- Full training + evaluation loop, supporting strategy performance comparison across train/test sets.
- Multi-metric visualization: cumulative return, rolling Sharpe, drawdown, volatility, MCRT chart, and weight dynamics.
- Market data preprocessing and reward function customization.

## ğŸš§ In Progress

- Multi-agent coordination: planned implementation of attention-based cooperation and adversarial signals.
- Strategy diversity boosting via agent-type heterogeneity and explicit diversity regularization.
- Long-term goal: simulate human-like investing logic under market regime shifts via interacting agents.

## ğŸ“Š Sample Output (Coming Soon)

## ğŸ“ Folder Structure (Planned)

ğŸ“¦ multi-agent-investment-system  
â”‚  
â”œâ”€â”€ agents/                             # ğŸ§  å¤šç§æŠ•èµ„ç­–ç•¥æ™ºèƒ½ä½“æ¨¡å—  
â”‚   â”œâ”€â”€ base_agent.py                       # æ™ºèƒ½ä½“é€šç”¨æ¥å£æŠ½è±¡ç±»  
â”‚   â”œâ”€â”€ RiskParityAgent.py                  # åŸºäºé£é™©å¹³ä»·ç­–ç•¥çš„æƒé‡åˆ†é…Agent  
â”‚   â”œâ”€â”€ CVaRDownsideVolAgent.py             # ä½¿ç”¨CVaRå’Œä¸‹è¡Œæ³¢åŠ¨ç‡æ§åˆ¶å°¾éƒ¨é£é™©çš„Agent  
â”‚   â”œâ”€â”€ DRLAgent.py                         # PPOç®—æ³•å®ç°çš„Actor-Criticæ™ºèƒ½ä½“  
â”‚   â””â”€â”€ calculate_portfolio_index_with_units_adjusted.py  # ç»„åˆå‡€å€¼è®¡ç®—å·¥å…·  
â”‚  
â”œâ”€â”€ controllers/                       # ğŸ§© æ™ºèƒ½ä½“ç­–ç•¥èåˆæ§åˆ¶å™¨  
â”‚   â”œâ”€â”€ debate_room.py                     # å¤šAgentç­–ç•¥é›†æˆä¸ç»Ÿä¸€è°ƒåº¦ä¸»æ§æ¨¡å—  
â”‚   â””â”€â”€ attention_fusion.py                # Attentionæœºåˆ¶é©±åŠ¨çš„AgentååŒæ¨¡å—ï¼ˆå¼€å‘ä¸­ï¼‰  
â”‚  
â”œâ”€â”€ configs/                          # âš™ï¸ é…ç½®æ–‡ä»¶ç›®å½•ï¼ˆè®­ç»ƒå‚æ•°ç­‰ï¼‰  
â”‚  
â”œâ”€â”€ data/                             # ğŸ“Š æ•°æ®æºä¸å®éªŒè¾“å‡ºç›®å½•  
â”‚   â”œâ”€â”€ èµ„äº§æ± .xlsx                         # å¤šèµ„äº§å†å²ä»·æ ¼æ•°æ®  
â”‚   â”œâ”€â”€ ä¸­è¯å¤šèµ„äº§é£é™©å¹³ä»·æŒ‡æ•°.xlsx           # ç”¨äºå¯¹æ¯”åˆ†æçš„å®é™…æŒ‡æ•°  
â”‚   â””â”€â”€ agent_performance_comparison.png   # å¤šç­–ç•¥å‡€å€¼è¡¨ç°å¯¹æ¯”å›¾  
â”‚  
â”œâ”€â”€ utils/                            # ğŸ”§ è¾…åŠ©æ¨¡å—  
â”‚   â””â”€â”€ llm_tools.py                      # é¢„ç•™ç”¨äºæœªæ¥ LLM Agent çš„æ¥å£æ¨¡å—  
â”‚  
â”œâ”€â”€ main.py                           # ğŸš€ ç³»ç»Ÿä¸»è¿è¡Œå…¥å£ï¼ˆè®­ç»ƒ+è¯„ä¼°+å¯è§†åŒ–ï¼‰  
â”‚  
â”œâ”€â”€ README.md                         # ğŸ“˜ é¡¹ç›®è¯´æ˜æ–‡æ¡£  
â””â”€â”€ requirements.txt                  # ğŸ“¦ Pythonè¿è¡Œç¯å¢ƒä¾èµ–æ¸…å•  

